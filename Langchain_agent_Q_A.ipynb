{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain openai -q"
      ],
      "metadata": {
        "id": "AkFz6H3UQVVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install unstructured -q\n",
        "!pip install unstructured[local-inference] -q\n",
        "!pip install detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2 -q\n",
        "!apt-get install poppler-utils"
      ],
      "metadata": {
        "id": "WPW-9GdjQVSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import pinecone\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain\n"
      ],
      "metadata": {
        "id": "_DXX6_WqWjV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"]=\"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\""
      ],
      "metadata": {
        "id": "RwuJlROXQVPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade pillow==6.2.2 "
      ],
      "metadata": {
        "id": "aNVOo90AWFwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import DirectoryLoader\n",
        "\n",
        "directory = '/content/sample_data/data'\n",
        "\n",
        "def load_docs(directory):\n",
        "\n",
        "  loader = DirectoryLoader(directory)\n",
        "  documents = loader.load()\n",
        "  return documents\n",
        "\n",
        "documents = load_docs(directory)\n",
        "len(documents)\n"
      ],
      "metadata": {
        "id": "RN-sprTAQVNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken -q"
      ],
      "metadata": {
        "id": "-kkoWbkRQVCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_docs(documents, chunk_size=1000, chunk_overlap=20):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "  docs = text_splitter.split_documents(documents)\n",
        "  return docs\n",
        "\n",
        "docs = split_docs(documents)\n",
        "print(len(docs))"
      ],
      "metadata": {
        "id": "WquCqIhIUmhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(model=\"text-davinci-002\")"
      ],
      "metadata": {
        "id": "qw7DsV_vxZPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pinecone-client -q"
      ],
      "metadata": {
        "id": "CnTpNjhNWt6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(\n",
        "    api_key=\"0b8494ce-c994-4389-9b59-7cd4d94f0f3d\",\n",
        "    environment=\"us-west4-gcp-free\"\n",
        ")\n",
        "\n",
        "index_name = \"myindex\"\n",
        "\n",
        "index = Pinecone.from_documents(docs, embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "WEUhYVJEW8Wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_similiar_docs(query, k=2, score=False):\n",
        "  if score:\n",
        "    similar_docs = index.similarity_search_with_score(query, k=k)\n",
        "  else:\n",
        "    similar_docs = index.similarity_search(query, k=k)\n",
        "  return similar_docs"
      ],
      "metadata": {
        "id": "fO0jPZJqX9iP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gpt-3.5-turbo\"\n",
        "llm = OpenAI(model_name=model_name)\n",
        "\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "DWTMSm7AUDg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(query):\n",
        "  similar_docs = get_similiar_docs(query)\n",
        "  answer = chain.run(input_documents=similar_docs, question=query)\n",
        "  return answer"
      ],
      "metadata": {
        "id": "HoTnhhZfUDkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}